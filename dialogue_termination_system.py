"""
æ™ºèƒ½å¯¹è¯ç»“æŸç³»ç»Ÿ (Intelligent Dialogue Termination System)

æ”¯æŒè‡ªç„¶çš„å¯¹è¯ç»“æŸæ¡ä»¶:
1. ç”¨æˆ·ä¸æƒ³ç»§ç»­(hesitancy detection)
2. AI åˆ¤æ–­ä¿¡æ¯æ”¶é›†å®Œæˆ
3. èŠå¤©è‡ªç„¶ç»“æŸ(è¯é¢˜è€—å°½)
4. æƒ…ç»ªä¿¡å·(ç–²æƒ«/ä¸è€çƒ¦)
"""

from typing import Dict, List, Tuple, Optional
from enum import Enum
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
import json


# ============================================================================
# å¯¹è¯ç»“æŸæ¡ä»¶æšä¸¾
# ============================================================================

class TerminationReason(str, Enum):
    """å¯¹è¯ç»“æŸåŸå› """
    USER_HESITANT = "user_hesitant"           # ç”¨æˆ·çŠ¹è±«/ä¸æƒ³ç»§ç»­
    INFO_COLLECTED = "info_collected"         # ä¿¡æ¯æ”¶é›†å®Œæˆ
    NATURAL_END = "natural_end"               # è‡ªç„¶ç»“æŸ
    USER_TIRED = "user_tired"                 # ç”¨æˆ·ç–²æƒ«
    TOPIC_EXHAUSTED = "topic_exhausted"       # è¯é¢˜è€—å°½
    MAX_TURNS = "max_turns_reached"           # è¾¾åˆ°æœ€å¤§è½®æ•°
    USER_REQUEST = "user_request_end"         # ç”¨æˆ·ä¸»åŠ¨è¦æ±‚ç»“æŸ


class TerminationSignal(BaseModel):
    """å¯¹è¯ç»“æŸä¿¡å·"""
    should_terminate: bool = Field(description="æ˜¯å¦åº”è¯¥ç»“æŸå¯¹è¯")
    reason: Optional[TerminationReason] = Field(description="ç»“æŸåŸå› ")
    confidence: float = Field(description="ç½®ä¿¡åº¦ 0-1")
    explanation: str = Field(description="åˆ¤æ–­ä¾æ®")


# ============================================================================
# ç”¨æˆ·çŠ¹è±«æ£€æµ‹å™¨ (User Hesitancy Detector)
# ============================================================================

class HesitancyDetector:
    """æ£€æµ‹ç”¨æˆ·æ˜¯å¦ä¸æƒ³ç»§ç»­å¯¹è¯"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        
        self.prompt = ChatPromptTemplate.from_template(
            """ä½ æ˜¯ä¸€ä¸ªå¿ƒç†åˆ†æä¸“å®¶,ä¸“é—¨åˆ†æç”¨æˆ·çš„å¯¹è¯æ„æ„¿ã€‚

å¯¹è¯å†å²(æœ€è¿‘5è½®):
{conversation_history}

ç”¨æˆ·æœ€æ–°å›å¤:
"{user_message}"

è¯·åˆ†æç”¨æˆ·æ˜¯å¦æ˜¾ç¤ºå‡ºä»¥ä¸‹ä¿¡å·:
1. çŠ¹è±«/æ•·è¡: å›å¤å¾ˆçŸ­ã€"å—¯"ã€"è¿˜å¥½"ã€"éšä¾¿"
2. å›é¿: ä¸æ„¿æ·±å…¥è¯é¢˜ã€è½¬ç§»è¯é¢˜ã€å›ç­”å«ç³Š
3. ç–²æƒ«: "æœ‰ç‚¹ç´¯äº†"ã€"æ”¹å¤©èŠ"ã€å›å¤é—´éš”å˜é•¿
4. ä¸è€çƒ¦: "å°±è¿™æ ·å§"ã€"å·®ä¸å¤šäº†"ã€è¯­æ°”å˜å†·
5. æ˜ç¡®æ‹’ç»: "ä¸æƒ³è¯´"ã€"ä¸å¤ªæ–¹ä¾¿"ã€"ä¸‹æ¬¡å†èŠ"

è¯·è¾“å‡º JSON æ ¼å¼(ä¸è¦ä»»ä½•è§£é‡Š):
{{
  "should_terminate": true/false,
  "reason": "user_hesitant/user_tired/user_request_end/null",
  "confidence": 0.0-1.0,
  "explanation": "åˆ¤æ–­ä¾æ®"
}}""")
    
    def detect(self, user_message: str, conversation_history: List[Dict]) -> TerminationSignal:
        """æ£€æµ‹ç”¨æˆ·æ˜¯å¦æƒ³ç»“æŸå¯¹è¯"""
        
        chain = self.prompt | self.llm
        
        response = chain.invoke({
            "user_message": user_message,
            "conversation_history": self._format_history(conversation_history)
        })
        
        # è§£æå“åº”
        return self._parse_response(response.content)
    
    def _format_history(self, history: List[Dict]) -> str:
        """æ ¼å¼åŒ–å¯¹è¯å†å²"""
        if not history:
            return "(å¯¹è¯åˆšå¼€å§‹)"
        
        lines = []
        for msg in history[-5:]:  # åªçœ‹æœ€è¿‘5è½®
            role = "AI" if msg.get("role") == "ai" else "ç”¨æˆ·"
            lines.append(f"{role}: {msg.get('content', '')}")
        return "\n".join(lines)
    
    def _parse_response(self, content: str) -> TerminationSignal:
        """è§£æ LLM å“åº”"""
        try:
            # æ¸…ç† JSON
            content = content.strip()
            if content.startswith("```json"):
                content = content.split("```json")[1].split("```")[0].strip()
            elif content.startswith("```"):
                content = content.split("```")[1].split("```")[0].strip()
            
            data = json.loads(content)
            return TerminationSignal(**data)
        except:
            # é»˜è®¤ä¸ç»“æŸ
            return TerminationSignal(
                should_terminate=False,
                reason=None,
                confidence=0.0,
                explanation="è§£æå¤±è´¥,ç»§ç»­å¯¹è¯"
            )


# ============================================================================
# ä¿¡æ¯å®Œæ•´åº¦æ£€æµ‹å™¨ (Information Completeness Detector)
# ============================================================================

class InfoCompletenessDetector:
    """æ£€æµ‹ Onboarding ä¿¡æ¯æ˜¯å¦æ”¶é›†å®Œæˆ"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        
        # å¿…é¡»æ”¶é›†çš„ä¿¡æ¯ç»´åº¦
        self.required_dimensions = [
            "æ•™è‚²èƒŒæ™¯ (å­¦å†/å­¦æ ¡)",
            "å·¥ä½œèŒä¸š (è¡Œä¸š/å¿™ç¢Œç¨‹åº¦)",
            "å®¶åº­èƒŒæ™¯ (ç‹¬ç”Ÿ/çˆ¶æ¯/èµ„äº§æƒ…å†µ)",
            "ç”Ÿæ´»æ–¹å¼ (çƒŸé…’/ä½œæ¯)",
            "æ‹çˆ±é£æ ¼ (ä¾æ‹ç±»å‹/ç²˜äººç¨‹åº¦)",
            "çº¦ä¼šåå¥½ (ç†æƒ³å‹/é›·ç‚¹)"
        ]
        
        self.prompt = ChatPromptTemplate.from_template(
            """ä½ æ˜¯ AI çº¢å¨˜çš„æ•°æ®è´¨é‡å®˜ï¼Œæ­£åœ¨è¯„ä¼°æ˜¯å¦å·²ç»æ”¶é›†åˆ°è¶³å¤Ÿçš„ç”¨æˆ·ç”»åƒæ•°æ®ã€‚

å¿…é¡»æ”¶é›†çš„æ ¸å¿ƒç»´åº¦:
{required_dimensions}

å®Œæ•´å¯¹è¯è®°å½•:
{full_conversation}

è¯·ä¸¥æ ¼è¯„ä¼°:
1. å“ªäº›ç»´åº¦å·²ç»**å……åˆ†æ”¶é›†**? (ä¾‹å¦‚: æ˜ç¡®çŸ¥é“æ˜¯æœ¬ç§‘ã€ä¸æŠ½çƒŸã€ç‹¬ç”Ÿå­å¥³ã€å®¶åº­ç»æµæ— è´Ÿæ‹…)
2. å“ªäº›ç»´åº¦**è¿˜ç¼ºå¤±**æˆ–**å¤ªæ¨¡ç³Š**? (ä¾‹å¦‚: åªè¯´äº†æœ‰å¼Ÿå¼Ÿï¼Œæ²¡è¯´çˆ¶æ¯æƒ…å†µ; æˆ–è€…åªè¯´äº†å·¥ä½œï¼Œæ²¡è¯´æ”¶å…¥èŒƒå›´)
3. æ˜¯å¦å¯ä»¥ç»“æŸè®¿è°ˆ?

è¯„ä¼°æ ‡å‡†:
- å¿…é¡»è¦†ç›–è‡³å°‘ 5/6 ä¸ªæ ¸å¿ƒç»´åº¦ã€‚
- å¯¹äº"ç¼ºå¤±"çš„ç»´åº¦ï¼Œå¿…é¡»æ˜¯ç”¨æˆ·æ˜ç¡®æ‹’ç»å›ç­”æˆ–æ— æ³•è·å–ï¼Œå¦åˆ™åº”ç»§ç»­è¯¢é—®ã€‚

è¯·è¾“å‡º JSON æ ¼å¼(ä¸è¦ä»»ä½•è§£é‡Š):
{{
  "should_terminate": true/false,
  "reason": "info_collected/null",
  "confidence": 0.0-1.0,
  "explanation": "å·²æ”¶é›†: [...] / ç¼ºå¤±: [...]",
  "collected_dimensions": ["æ•™è‚²", "å·¥ä½œ", ...],
  "missing_dimensions": ["å®¶åº­èµ„äº§", ...]
}}""")
    
    def detect(self, full_conversation: List[Dict], min_turns: int = 8) -> TerminationSignal:
        """æ£€æµ‹ä¿¡æ¯æ˜¯å¦æ”¶é›†å®Œæˆ"""
        
        # åŸºæœ¬æ£€æŸ¥: è‡³å°‘å¯¹è¯ min_turns è½®
        if len(full_conversation) < min_turns * 2:  # *2 å› ä¸ºæ¯è½®æœ‰ AI å’Œ user
            return TerminationSignal(
                should_terminate=False,
                reason=None,
                confidence=1.0,
                explanation=f"å¯¹è¯ä¸è¶³ {min_turns} è½®,ç»§ç»­æ”¶é›†"
            )
        
        chain = self.prompt | self.llm
        
        response = chain.invoke({
            "required_dimensions": ", ".join(self.required_dimensions),
            "full_conversation": self._format_conversation(full_conversation)
        })
        
        return self._parse_response(response.content)
    
    def _format_conversation(self, conversation: List[Dict]) -> str:
        """æ ¼å¼åŒ–å®Œæ•´å¯¹è¯"""
        lines = []
        for msg in conversation:
            role = "AI" if msg.get("role") == "ai" else "ç”¨æˆ·"
            lines.append(f"{role}: {msg.get('content', '')}")
        return "\n".join(lines)
    
    def _parse_response(self, content: str) -> TerminationSignal:
        """è§£æå“åº”"""
        try:
            content = content.strip()
            if content.startswith("```json"):
                content = content.split("```json")[1].split("```")[0].strip()
            elif content.startswith("```"):
                content = content.split("```")[1].split("```")[0].strip()
            
            data = json.loads(content)
            return TerminationSignal(
                should_terminate=data["should_terminate"],
                reason=data.get("reason"),
                confidence=data["confidence"],
                explanation=data["explanation"]
            )
        except:
            return TerminationSignal(
                should_terminate=False,
                reason=None,
                confidence=0.0,
                explanation="è§£æå¤±è´¥,ç»§ç»­æ”¶é›†"
            )


# ============================================================================
# ç¤¾äº¤å¯¹è¯è‡ªç„¶ç»“æŸæ£€æµ‹å™¨ (Natural Conversation End Detector)
# ============================================================================

class NaturalEndDetector:
    """æ£€æµ‹ç¤¾äº¤å¯¹è¯æ˜¯å¦è‡ªç„¶ç»“æŸ"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        
        self.prompt = ChatPromptTemplate.from_template(
            """ä½ æ˜¯å¯¹è¯åˆ†æä¸“å®¶,åˆ¤æ–­ä¸¤ä¸ªäººçš„èŠå¤©æ˜¯å¦åˆ°äº†è‡ªç„¶ç»“æŸç‚¹ã€‚

æœ€è¿‘å¯¹è¯(æœ€å8æ¡):
{recent_conversation}

å®Œæ•´å¯¹è¯ç»Ÿè®¡:
- æ€»æ¶ˆæ¯æ•°: {total_messages}
- æŒç»­æ—¶é—´: {duration}

è¯·åˆ†ææ˜¯å¦å‡ºç°ä»¥ä¸‹ä¿¡å·:
1. è¯é¢˜è€—å°½: å¼€å§‹é‡å¤ã€æ— æ–°è¯é¢˜ã€æ²‰é»˜å¢å¤š
2. ç¤¼è²Œç»“æŸ: "ä»Šå¤©èŠå¾—å¾ˆå¼€å¿ƒ"ã€"æ”¹å¤©å†èŠ"ã€"è¦å»å¿™äº†"
3. çº¦å®šåç»­: "é‚£æˆ‘ä»¬å‘¨æœ«è§"ã€"åŠ ä¸ªå¾®ä¿¡å§"
4. è‡ªç„¶æ”¶å°¾: ç›¸äº’å‘Šåˆ«ã€å¯¹è¯å®Œæ•´é—­ç¯
5. å†·åœº: è¿ç»­ç®€çŸ­å›å¤ã€"å—¯å—¯"ã€"å¥½çš„"

æ³¨æ„: 20æ¡æ¶ˆæ¯ä»¥ä¸‹ä¸åº”è¯¥ç»“æŸ(è¿˜åœ¨çƒ­èŠæœŸ)

è¯·è¾“å‡º JSON æ ¼å¼(ä¸è¦ä»»ä½•è§£é‡Š):
{{
  "should_terminate": true/false,
  "reason": "natural_end/topic_exhausted/null",
  "confidence": 0.0-1.0,
  "explanation": "åˆ¤æ–­ä¾æ®"
}}""")
    
    def detect(self, full_conversation: List[Dict], min_messages: int = 20) -> TerminationSignal:
        """æ£€æµ‹æ˜¯å¦è‡ªç„¶ç»“æŸ"""
        
        # åŸºæœ¬æ£€æŸ¥: è‡³å°‘ min_messages æ¡
        if len(full_conversation) < min_messages:
            return TerminationSignal(
                should_terminate=False,
                reason=None,
                confidence=1.0,
                explanation=f"æ¶ˆæ¯ä¸è¶³ {min_messages} æ¡,è¿˜åœ¨çƒ­èŠæœŸ"
            )
        
        # è®¡ç®—æŒç»­æ—¶é—´
        duration = self._calculate_duration(full_conversation)
        
        chain = self.prompt | self.llm
        
        response = chain.invoke({
            "recent_conversation": self._format_recent(full_conversation),
            "total_messages": len(full_conversation),
            "duration": duration
        })
        
        return self._parse_response(response.content)
    
    def _format_recent(self, conversation: List[Dict]) -> str:
        """æ ¼å¼åŒ–æœ€è¿‘å¯¹è¯"""
        lines = []
        for msg in conversation[-8:]:
            sender = f"ç”¨æˆ·{msg.get('sender_id', 'A')}"
            lines.append(f"{sender}: {msg.get('content', '')}")
        return "\n".join(lines)
    
    def _calculate_duration(self, conversation: List[Dict]) -> str:
        """è®¡ç®—å¯¹è¯æŒç»­æ—¶é—´"""
        if not conversation or len(conversation) < 2:
            return "åˆšå¼€å§‹"
        
        first_ts = conversation[0].get("timestamp")
        last_ts = conversation[-1].get("timestamp")
        
        if first_ts and last_ts:
            duration = last_ts - first_ts
            minutes = duration.total_seconds() / 60
            return f"{int(minutes)} åˆ†é’Ÿ"
        
        return "æœªçŸ¥"
    
    def _parse_response(self, content: str) -> TerminationSignal:
        """è§£æå“åº”"""
        try:
            content = content.strip()
            if content.startswith("```json"):
                content = content.split("```json")[1].split("```")[0].strip()
            elif content.startswith("```"):
                content = content.split("```")[1].split("```")[0].strip()
            
            data = json.loads(content)
            return TerminationSignal(**data)
        except:
            return TerminationSignal(
                should_terminate=False,
                reason=None,
                confidence=0.0,
                explanation="è§£æå¤±è´¥,ç»§ç»­å¯¹è¯"
            )


# ============================================================================
# ç»¼åˆå¯¹è¯ç»ˆæ­¢ç®¡ç†å™¨ (Dialogue Termination Manager)
# ============================================================================

class DialogueTerminationManager:
    """ç»¼åˆç®¡ç†å¯¹è¯ç»ˆæ­¢é€»è¾‘"""
    
    def __init__(self, llm):
        self.hesitancy_detector = HesitancyDetector(llm)
        self.info_detector = InfoCompletenessDetector(llm)
        self.natural_end_detector = NaturalEndDetector(llm)
    
    def should_terminate_onboarding(
        self, 
        conversation: List[Dict],
        min_turns: int = 8,
        max_turns: int = 20
    ) -> Tuple[bool, TerminationSignal]:
        """åˆ¤æ–­ onboarding å¯¹è¯æ˜¯å¦åº”è¯¥ç»“æŸ"""
        
        # 1. æ£€æŸ¥æœ€å¤§è½®æ•°
        num_turns = len(conversation) // 2
        if num_turns >= max_turns:
            return True, TerminationSignal(
                should_terminate=True,
                reason=TerminationReason.MAX_TURNS,
                confidence=1.0,
                explanation=f"è¾¾åˆ°æœ€å¤§è½®æ•° {max_turns}"
            )
        
        # 2. æ£€æŸ¥æœ€å°è½®æ•°
        if num_turns < min_turns:
            return False, TerminationSignal(
                should_terminate=False,
                reason=None,
                confidence=1.0,
                explanation=f"æœªè¾¾åˆ°æœ€å°è½®æ•° {min_turns}"
            )
        
        # 3. æ£€æŸ¥ç”¨æˆ·çŠ¹è±«
        if len(conversation) >= 2:
            last_user_msg = None
            for msg in reversed(conversation):
                if msg.get("role") == "user":
                    last_user_msg = msg.get("content", "")
                    break
            
            if last_user_msg:
                hesitancy_signal = self.hesitancy_detector.detect(
                    last_user_msg, 
                    conversation
                )
                
                if hesitancy_signal.should_terminate and hesitancy_signal.confidence > 0.7:
                    return True, hesitancy_signal
        
        # 4. æ£€æŸ¥ä¿¡æ¯å®Œæ•´åº¦
        info_signal = self.info_detector.detect(conversation, min_turns)
        
        if info_signal.should_terminate and info_signal.confidence > 0.8:
            return True, info_signal
        
        # é»˜è®¤ç»§ç»­
        return False, TerminationSignal(
            should_terminate=False,
            reason=None,
            confidence=0.0,
            explanation="ç»§ç»­æ”¶é›†ä¿¡æ¯"
        )
    
    def should_terminate_social_chat(
        self,
        conversation: List[Dict],
        min_messages: int = 20,
        max_messages: int = 60
    ) -> Tuple[bool, TerminationSignal]:
        """åˆ¤æ–­ç¤¾äº¤èŠå¤©æ˜¯å¦åº”è¯¥ç»“æŸ"""
        
        # 1. æ£€æŸ¥æœ€å¤§æ¶ˆæ¯æ•°
        if len(conversation) >= max_messages:
            return True, TerminationSignal(
                should_terminate=True,
                reason=TerminationReason.MAX_TURNS,
                confidence=1.0,
                explanation=f"è¾¾åˆ°æœ€å¤§æ¶ˆæ¯æ•° {max_messages}"
            )
        
        # 2. æ£€æŸ¥æœ€å°æ¶ˆæ¯æ•°
        if len(conversation) < min_messages:
            return False, TerminationSignal(
                should_terminate=False,
                reason=None,
                confidence=1.0,
                explanation=f"æœªè¾¾åˆ°æœ€å°æ¶ˆæ¯æ•° {min_messages}"
            )
        
        # 3. æ£€æŸ¥è‡ªç„¶ç»“æŸ
        natural_signal = self.natural_end_detector.detect(conversation, min_messages)
        
        if natural_signal.should_terminate and natural_signal.confidence > 0.7:
            return True, natural_signal
        
        # 4. æ£€æŸ¥ç”¨æˆ·ç–²æƒ«(æ£€æŸ¥æœ€åä¸€æ¡æ¶ˆæ¯)
        if len(conversation) >= 1:
            last_msg = conversation[-1].get("content", "")
            hesitancy_signal = self.hesitancy_detector.detect(last_msg, conversation)
            
            if hesitancy_signal.should_terminate and hesitancy_signal.confidence > 0.8:
                return True, hesitancy_signal
        
        # é»˜è®¤ç»§ç»­
        return False, TerminationSignal(
            should_terminate=False,
            reason=None,
            confidence=0.0,
            explanation="ç»§ç»­èŠå¤©"
        )


# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================================================

def demo_termination_detection():
    """æ¼”ç¤ºç»ˆæ­¢æ£€æµ‹åŠŸèƒ½"""
    
    from langchain_openai import ChatOpenAI
    import os
    
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.7,
        api_key=os.getenv("OPENAI_API_KEY")
    )
    
    manager = DialogueTerminationManager(llm)
    
    print("=" * 80)
    print("ğŸ¯ å¯¹è¯ç»ˆæ­¢æ£€æµ‹ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 80)
    
    # ç¤ºä¾‹ 1: ç”¨æˆ·çŠ¹è±«
    print("\nåœºæ™¯ 1: ç”¨æˆ·æ˜¾ç¤ºçŠ¹è±«ä¿¡å·")
    print("-" * 80)
    conversation = [
        {"role": "ai", "content": "èƒ½èŠèŠä½ çš„æ„Ÿæƒ…ç»å†å—?"},
        {"role": "user", "content": "å—¯...è¿™ä¸ª...ä¸å¤ªæƒ³è¯´..."}
    ]
    
    should_end, signal = manager.should_terminate_onboarding(conversation, min_turns=1)
    print(f"æ˜¯å¦ç»“æŸ: {should_end}")
    print(f"åŸå› : {signal.reason}")
    print(f"ç½®ä¿¡åº¦: {signal.confidence}")
    print(f"è¯´æ˜: {signal.explanation}")
    
    # ç¤ºä¾‹ 2: ä¿¡æ¯æ”¶é›†å®Œæˆ
    print("\nåœºæ™¯ 2: ä¿¡æ¯æ”¶é›†å®Œæ•´")
    print("-" * 80)
    conversation = [
        {"role": "ai", "content": "ä½ çš„å·¥ä½œæ˜¯ä»€ä¹ˆ?"},
        {"role": "user", "content": "æˆ‘æ˜¯äº§å“ç»ç†,åœ¨äº’è”ç½‘å…¬å¸å·¥ä½œ"},
        {"role": "ai", "content": "å¹³æ—¶æœ‰ä»€ä¹ˆå…´è¶£çˆ±å¥½?"},
        {"role": "user", "content": "å–œæ¬¢è·‘æ­¥ã€çœ‹ç”µå½±ã€æ—…è¡Œ"},
        {"role": "ai", "content": "ç†æƒ³çš„å¦ä¸€åŠæ˜¯ä»€ä¹ˆæ ·çš„?"},
        {"role": "user", "content": "å¸Œæœ›å¯¹æ–¹ç‹¬ç«‹ã€æœ‰è¶£ã€ä¸‰è§‚å¥‘åˆ"},
        {"role": "ai", "content": "å®¶åº­æƒ…å†µå¦‚ä½•?"},
        {"role": "user", "content": "ç‹¬ç”Ÿå­å¥³,çˆ¶æ¯é€€ä¼‘äº†"},
        {"role": "ai", "content": "ä½ è§‰å¾—æ„Ÿæƒ…ä¸­æœ€é‡è¦çš„æ˜¯ä»€ä¹ˆ?"},
        {"role": "user", "content": "æˆ‘è§‰å¾—çœŸè¯šå’Œæ²Ÿé€šæœ€é‡è¦"}
    ]
    
    should_end, signal = manager.should_terminate_onboarding(conversation, min_turns=4)
    print(f"æ˜¯å¦ç»“æŸ: {should_end}")
    print(f"åŸå› : {signal.reason}")
    print(f"ç½®ä¿¡åº¦: {signal.confidence}")
    print(f"è¯´æ˜: {signal.explanation}")
    
    # ç¤ºä¾‹ 3: ç¤¾äº¤èŠå¤©è‡ªç„¶ç»“æŸ
    print("\nåœºæ™¯ 3: ç¤¾äº¤å¯¹è¯è‡ªç„¶ç»“æŸ")
    print("-" * 80)
    from datetime import datetime, timedelta
    
    base_time = datetime.now()
    conversation = []
    
    messages_content = [
        "Hi,çœ‹åˆ°ä½ ä¹Ÿå–œæ¬¢æ‘„å½±!",
        "å¯¹å‘€,ä¸è¿‡æˆ‘æ˜¯ä¸šä½™çš„å“ˆå“ˆ",
        "æ²¡äº‹,æˆ‘ä¹Ÿæ˜¯ä¸šä½™çš„~ä½ ä¸€èˆ¬æ‹ä»€ä¹ˆ?",
        "é£æ™¯ä¸ºä¸»,å¶å°”æ‹äººåƒ",
        # ... å‡è®¾ä¸­é—´æœ‰å¾ˆå¤šå¯¹è¯
        "ä»Šå¤©èŠå¾—å¾ˆå¼€å¿ƒ!",
        "æˆ‘ä¹Ÿæ˜¯!é‚£æˆ‘ä»¬å‘¨æœ«ä¸€èµ·å»æ‹ç…§å§?",
        "å¥½å•Š!é‚£å°±è¿™æ ·è¯´å®šäº†~",
        "å—¯å—¯,åˆ°æ—¶å€™è”ç³»!",
        "å¥½çš„,æ‹œæ‹œ~",
        "æ‹œæ‹œ!"
    ]
    
    for i, content in enumerate(messages_content):
        conversation.append({
            "sender_id": f"user_{i % 2}",
            "content": content,
            "timestamp": base_time + timedelta(minutes=i*3)
        })
    
    # å¡«å……åˆ°è‡³å°‘ 20 æ¡
    while len(conversation) < 20:
        conversation.insert(-4, {
            "sender_id": "user_0",
            "content": "èŠå¤©å†…å®¹...",
            "timestamp": base_time + timedelta(minutes=len(conversation)*3)
        })
    
    should_end, signal = manager.should_terminate_social_chat(conversation, min_messages=15)
    print(f"æ˜¯å¦ç»“æŸ: {should_end}")
    print(f"åŸå› : {signal.reason}")
    print(f"ç½®ä¿¡åº¦: {signal.confidence}")
    print(f"è¯´æ˜: {signal.explanation}")
    
    print("\n" + "=" * 80)
    print("âœ¨ æ¼”ç¤ºå®Œæˆ!")


if __name__ == "__main__":
    demo_termination_detection()
